//  Copyright (c) 2010 Marc Fauconneau
//
// Permission is hereby granted, free of charge, to any person or organization
// obtaining a copy of the software and accompanying documentation covered by
// this license (the "Software") to use, reproduce, display, distribute,
// execute, and transmit the Software, and to prepare derivative works of the
// Software, and to permit third-parties to whom the Software is furnished to
// do so, all subject to the following:
//
// The copyright notices in the Software and this entire statement, including
// the above license grant, this restriction and the following disclaimer,
// must be included in all copies of the Software, in whole or in part, and
// all derivative works of the Software, unless such copies or derivative
// works are solely in the form of machine-executable object code generated by
// a source language processor.
//
// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
// FITNESS FOR A PARTICULAR PURPOSE, TITLE AND NON-INFRINGEMENT. IN NO EVENT
// SHALL THE COPYRIGHT HOLDERS OR ANYONE DISTRIBUTING THE SOFTWARE BE LIABLE
// FOR ANY DAMAGES OR OTHER LIABILITY, WHETHER IN CONTRACT, TORT OR OTHERWISE,
// ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER
// DEALINGS IN THE SOFTWARE.

import ctypes.(CInt);
import hashing.(hash);
import libc.(memset);
import unsafe.memory.(allocateUninitializedValues, freeUninitializedValues);
import unsafe.casts.(refToRvalue, rvalueToRef);
import unsafe.compositetypes.*;
import unsafe.coordinates.(
    ContiguousCoordinate, CoordinateRange,
    assignRange, initializeRange, copyRange, destroyRange
);
import unsafe.valuesemantics.*;


//
// hash map type
//

define HashMap['K,'V] as NewType(TwoHash[MapEntry['K,'V]]);

overload HashMap['K,'V]() = HashMap['K,'V](TwoHash[MapEntry['K,'V]]());
overload size(m:HashMap['K, 'V]) = (*m).size;

lookup(m:HashMap['K, 'V], key:'K)
    = maybe(entryp(*m, key), (entp) -> just(&entp^.value));

put(ref m:HashMap['K, 'V], key:'K, forward value:'V) {
    ref hash = *m;
    var mEntp = entryp(hash, key);
    if (just?(mEntp)) {
        var entp = required(mEntp);
        entp^.value = value;
        return entp;
    } else {
        return allocEntry(hash, key, MapEntry['K,'V](key, value));
    }
}

remove(ref m:HashMap['K, 'V], key:'K) {
    freeEntry(*m, key);
}

clear(ref m:HashMap['K,'V]) {
    clearEntries(*m);
}

items(m:HashMap['K,'V]) = HashIterator[MapEntry['K,'V]](*m);


//
// index operator
//

overload index(ref m:HashMap['K, 'V], key:'K) | DefaultInitializable?('V) {
    ref hash = *m;
    var mEntp = entryp(hash, key);
    if (just?(mEntp)) {
        return ref valueFromEntry(required(mEntp)^);
    } else {
        return ref valueFromEntry(allocEntry(hash, key, MapEntry['K,'V](key, 'V()))^);
    }
}


//
// iterator
//

define HashIterator['E] as RecordType(
    hashp:Pointer[TwoHash['E]],
    i:Int,
    j:UInt,
    entryMask:UInt,
);

overload HashIterator['E](h:TwoHash['E]) --> returned:HashIterator['E] {
    returned <-- HashIterator['E](&h, 0, 0u, 0u);
    refillMask(returned);
}

overload hasFront?(i:HashIterator['E]) = i.entryMask != 0u;

overload front(i:HashIterator['E]) {
    assert(-> i.entryMask != 0u);
    var kmask = lowBitMask(i.entryMask);
    var k = lowBit(kmask);
    ref e = i.hashp^.tables[i.i].begin[i.j].entries[k];
    return forward ..itemFromEntry(e);
}

overload incFront(ref i:HashIterator['E]) {
    assert(-> i.entryMask != 0u);
    var kmask = lowBitMask(i.entryMask);
    i.entryMask = bitandc(i.entryMask, kmask);
    if (i.entryMask == 0u) {
        nextBucket(i);
        refillMask(i);
    }
}

private nextBucket(ref i:HashIterator['E]) {
    i.j += 1u;
    if (i.j == tableSize(i.hashp^.tables[i.i])) {
        i.i += 1;
        i.j = 0u;
    }
}
private refillMask(ref i:HashIterator['E]) {
    ref hash = i.hashp^;

    while (true) {
        if (i.i == 2) return;
        for (k in Range(BucketSize))
            if (hash.tables[i.i].begin[i.j].hashBytes[k] != 255u)
                i.entryMask = bitor(i.entryMask, bitshl(1, k));
        if (i.entryMask != 0u) return;
        nextBucket(i);
    }
}

private lowBitMask(x) inline = bitand(x, -x);
private lowBit(mask_:'I) {
    var b = 0;
    var mask = mask_;
    for (x in Range(typeSize('I))) {
        switch (mask)
        case (1u)
            return b+0;
        case (2u)
            return b+1;
        case (4u)
            return b+2;
        case (8u)
            return b+3;
        case (16u)
            return b+4;
        case (32u)
            return b+5;
        case (64u)
            return b+6;
        case (128u)
            return b+7;
        b += 8;
        mask = bitshr(mask, 8);
    }
    assertUnreachable(->{}, "not a power of two");
}


//
// hash entry structures
//

private define MapEntry['K,'V] as RecordType(key:'K, value:'V);

private define keyMatch?;
private define entryHash;
private define itemFromEntry;
private define valueFromEntry;

overload keyMatch?(entry:MapEntry['K,'V], key:'K) = entry.key == key;
overload entryHash(entry:MapEntry['K,'V]) = largeHash(entry.key);
overload itemFromEntry(forward entry:MapEntry['K,'V])
    = forward ..*entry;
overload valueFromEntry(forward entry:MapEntry['K,'V]) = forward entry.value;


//
// twohash implementation
//

private define TwoHash['E] as RecordType(tables:Array[Table[Bucket['E]], 2], size:UInt);

overload TwoHash['E]() {
    var TableType = #Table[Bucket['E]];
    return TwoHash['E](
        Array[TableType, 2](TableType(0), TableType(0)),
        0u
    );
}

// tables

private define Table['B] as CompositeType(begin:ContiguousCoordinate['B], ln2_size:Int);

private tableSize(t:Table['B]) = bitshl(1u, t.ln2_size);
overload tableSize(ln2_size:'I) | Integer?('I) = bitshl(1u, ln2_size);

overload Table['B](ln2_size:Int) --> returned:Table['B] {
    var size = tableSize(ln2_size);
    returned.ln2_size <-- ln2_size;
    returned.begin <-- allocateUninitializedValues(size, 'B); //XXX aligned(16)
    try {
        initializeRange(returned.begin, returned.begin+size);
    } catch (ex) {
        freeUninitializedValues(returned.begin);
        throw ex;
    }
}
overload copy(t:Table['B]) --> returned:Table['B] {
    var size = tableSize(t);
    returned.ln2_size <-- t.ln2_size;
    returned.begin <-- allocateUninitializedValues(size, 'B); //XXX aligned(16)
    try {
        copyRange(returned.begin, t.begin, t.begin+size);
    } catch (ex) {
        freeUninitializedValues(returned.begin);
        throw ex;
    }
}
overload copyAssign(ref to:Table['B], from:Table['B]) {
    if (to.begin == from.begin) {
        assert(-> to.ln2_size == from.ln2_size);
        return;
    }

    var oldSize = tableSize(to), newSize = tableSize(from);
    if (to.begin == ContiguousCoordinate['B]()) {
        to <-- from;
    } else if (to.begin != ContiguousCoordinate['B]() and to.ln2_size >= from.ln2_size) {
        destroyRange(to.begin+newSize, to.begin+oldSize);
        to.ln2_size = from.ln2_size;
        assignRange(to.begin, from.begin, from.begin+newSize);
    } else {
        var newBegin = allocateUninitializedValues(newSize, 'B);
        try {
            copyRange(newBegin, from.begin, from.begin+newSize);
        } catch (ex) {
            freeUninitializedValues(newBegin);
            throw ex;
        }
        destroyRange(to.begin, to.begin+oldSize);
        freeUninitializedValues(to.begin);
        to.begin = newBegin;
        to.ln2_size = from.ln2_size;
    }
}
overload reset(ref t:Table['B]) {
    t.begin = ContiguousCoordinate['B]();
    t.ln2_size = 0;
}
overload destroy(ref t:Table['B]) {
    if (t.begin != ContiguousCoordinate['B]()) {
        destroyRange(t.begin, t.begin+tableSize(t));
        freeUninitializedValues(t.begin);
    }
}

// buckets

private alias BucketSize = 16;

private define Bucket['E] as CompositeType(
    hashBytes:Array[UInt8,BucketSize],
    entries:Array['E, BucketSize]
);

overload #InitializeDoesNotThrow?(Bucket['E]) = true;

overload Bucket['E]() --> returned:Bucket['E] {
    memset(OpaquePointer(&returned.hashBytes), CInt(255), UInt(BucketSize));
}
overload copy(b:Bucket['E]) --> returned:Bucket['E] {
    returned.hashBytes <-- b.hashBytes;
    for (i in Range(BucketSize))
        if (b.hashBytes[i] != 255u)
            returned.entries[i] <-- b.entries[i];
}
overload copyAssign(ref to:Bucket['E], from:Bucket['E]) {
    for (i in Range(BucketSize)) {
        if (to.hashBytes[i] != 255u and from.hashBytes[i] != 255u)
            to.entries[i] = from.entries[i];
        else if (to.hashBytes[i] != 255u /*and from.hashBytes[i] == 255u*/)
            destroy(to.entries[i]);
        else if (from.hashBytes[i] != 255u /*and to.hashBytes[i] == 255u*/)
            to.entries[i] <-- from.entries[i];

        to.hashBytes[i] = from.hashBytes[i];
    }
}
overload destroy(ref b:Bucket['E]) {
    for (i in Range(BucketSize))
        if (b.hashBytes[i] != 255u)
            destroy(b.entries[i]);
}

// entry management

private entryp(h:TwoHash['E], key) {
    var hash = splitHash(h, key);
    for (i in Range(2)) {
        for (j in Range(BucketSize)) {
            if (h.tables[i].begin[hash[i]].hashBytes[j] == hash[2]) {
                ref entry = h.tables[i].begin[hash[i]].entries[j];
                if (keyMatch?(entry, key))
                    return just(&entry);
            }
        }
    }
    return null('E);
}

private allocEntry(ref h:TwoHash['E], key, forward entry:'E) {
    assert(-> nothing?(entryp(h, key)));

    while (true) {
        var hash = splitHash(h, key);
        var entryCount = Array[Int,2](0,0);
        for (i in Range(2)) {
            for (j in Range(BucketSize)) {
                if (h.tables[i].begin[hash[i]].hashBytes[j] != 255u)
                    entryCount[i] += 1;
            }
        }

        if (min(entryCount[0], entryCount[1]) == BucketSize) {
            grow(h);
            continue;
        }

        var bi = if (entryCount[1] < entryCount[0]) 1 else 0;

        var entp = allocInBucket(h.tables[bi].begin[hash[bi]], entry, hash[2]);
        h.size += 1u;
        return entp;
    }
}

private freeEntry(ref h:TwoHash['E], key) {
    var hash = splitHash(h, key);
    for (i in Range(2)) {
        for (j in Range(BucketSize)) {
            if (h.tables[i].begin[hash[i]].hashBytes[j] == hash[2]) {
                ref bucket = h.tables[i].begin[hash[i]];
                ref entry = bucket.entries[j];
                if (keyMatch?(entry, key)) {
                    freeFromBucket(bucket, j);
                    h.size -= 1u;
                    return;
                }
            }
        }
    }
}

private clearEntries(ref h:TwoHash['E]) {
    for (i in Range(2)) {
        ref table = h.tables[i];
        ref begin = table.begin;
        for (ref bucket in CoordinateRange(begin, begin + tableSize(table)))
            clearBucket(bucket);
    }
    h.size = 0u;
}

// XXX rvalue analysis
overload allocEntry(ref h:TwoHash['E], key, rvalue entry:'E) {
    ref rentry = rvalueToRef(entry);

    assert(-> nothing?(entryp(h, key)));

    while (true) {
        var hash = splitHash(h, key);
        var entryCount = Array[Int,2](0,0);
        for (i in Range(2)) {
            for (j in Range(BucketSize)) {
                if (h.tables[i].begin[hash[i]].hashBytes[j] != 255u)
                    entryCount[i] += 1;
            }
        }

        if (min(entryCount[0], entryCount[1]) == BucketSize) {
            grow(h);
            continue;
        }

        var bi = if (entryCount[1] < entryCount[0]) 1 else 0;

        var entp = allocInBucket(h.tables[bi].begin[hash[bi]], refToRvalue(rentry), hash[2]);
        h.size += 1u;
        return entp;
    }
    assertUnreachable(->{});
}

private allocInBucket(ref b:Bucket['E], forward entry:'E, hashByte) {
    for (i in Range(BucketSize)) {
        if (b.hashBytes[i] == 255u) {
            b.hashBytes[i] = UInt8(hashByte);
            var entryp = &b.entries[i];
            entryp^ <-- entry;
            return entryp;
        }
    }
    assertUnreachable(->{});
}

// XXX rvalue analysis
overload allocInBucket(ref b:Bucket['E], rvalue entry:'E, hashByte) {
    ref rentry = rvalueToRef(entry);
    for (i in Range(BucketSize)) {
        if (b.hashBytes[i] == 255u) {
            b.hashBytes[i] = UInt8(hashByte);
            var entryp = &b.entries[i];
            entryp^ <-- refToRvalue(rentry);
            return entryp;
        }
    }
    assertUnreachable(->{});
}

private freeFromBucket(ref b:Bucket['E], index) {
    destroy(b.entries[index]);
    b.hashBytes[index] = 255u;
}

private clearBucket(ref b:Bucket['E]) {
    for (i in Range(BucketSize))
        if (b.hashBytes[i] != 255u)
            destroy(b.entries[i]);
    reset(b);
}

private grow(ref h:TwoHash['E]) {
    var i = 0;
    if (h.tables[0].ln2_size > h.tables[1].ln2_size)
        i = 1;

    var oldTable = move(h.tables[i]);
    h.tables[i] = Table[Bucket['E]](oldTable.ln2_size+1);

    for (j in Range(tableSize(oldTable)))
        for (k in Range(BucketSize))
            if (oldTable.begin[j].hashBytes[k] != 255u) {
                ref entry = oldTable.begin[j].entries[k];
                var hash = splitHash(h, entry);
                ref newBucket = h.tables[i].begin[hash[i]];
                allocInBucket(newBucket, entry, hash[2]);
            }
}

// hashing

private define splitHash;
overload splitHash(h:TwoHash['E], key:'K) = baseSplitHash(h, largeHash(key));
overload splitHash(h:TwoHash['E], entry:'E) = baseSplitHash(h, entryHash(entry));

private largeHash(x) {
    var h = UInt64(hash(x));
    var e = bitshr(h * 0x70010101_u64, 8);
    return e + bitshl(e, 32);
}

private baseSplitHash(h:TwoHash['E], hash:UInt64) {
    var hash1 = UInt(bitshr(hash, 8)),
        hash2 = UInt(bitshr(hash, 32)),
        lowHash = UInt(bitand(hash, 0x7fu));
    return Array[UInt, 3](
        bitand(hash1, tableSize(h.tables[0]) - 1u),
        bitand(hash2, tableSize(h.tables[1]) - 1u),
        lowHash
    );
}
